{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from load_data import load_data\n",
    "import torch\n",
    "from modules import GNN\n",
    "from train_model import train_model\n",
    "from subgraph_relevance import subgraph_original, subgraph_mp_transcription, subgraph_mp_forward_hook, get_H_transform\n",
    "from utils import create_ground_truth, get_feat_order_local_best_guess, get_auac_aupc, get_stats\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a function of model layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs, pos_idx, neg_idx = load_data('BA-2motif')\n",
    "\n",
    "model_dirs = ['gin-2-ba2motif.torch',\n",
    "            'gin-3-ba2motif.torch',\n",
    "            'gin-4-ba2motif.torch',\n",
    "            'gin-5-ba2motif.torch',\n",
    "            'gin-6-ba2motif.torch',\n",
    "            'gin-7-ba2motif.torch']\n",
    "\n",
    "g = graphs[44]\n",
    "S = [0,1,2,3]\n",
    "alpha = 0.\n",
    "verbose = False\n",
    "num_samples = 50\n",
    "sample_idx = np.random.choice(len(graphs),num_samples,replace=False)\n",
    "\n",
    "model_times = []\n",
    "\n",
    "nn = torch.load('models/'+model_dirs[1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmin(b): return -0.5*torch.log(1.0+torch.exp(-2*b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runtime experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs, pos_idx, neg_idx = load_data('BA-2motif')\n",
    "\n",
    "model_dirs = ['gin-2-ba2motif.torch',\n",
    "            'gin-3-ba2motif.torch',\n",
    "            'gin-4-ba2motif.torch',\n",
    "            'gin-5-ba2motif.torch',\n",
    "            'gin-6-ba2motif.torch',\n",
    "            'gin-7-ba2motif.torch']\n",
    "\n",
    "# g = graphs[44]\n",
    "S = [0,1,2,3]\n",
    "alpha = 0.\n",
    "verbose = False\n",
    "num_samples = 50\n",
    "sample_idx = np.random.choice(len(graphs),num_samples,replace=False)\n",
    "\n",
    "model_times = []\n",
    "\n",
    "for model_dir in tqdm(model_dirs):\n",
    "    ts = []\n",
    "    nn = torch.load('models/'+model_dir)\n",
    "    \n",
    "    t_temp = 0\n",
    "    for j, i in tqdm(enumerate(sample_idx)):\n",
    "        g = graphs[i]\n",
    "        timea = time.time()\n",
    "        subgraph_original(nn, g, S, alpha=alpha, gamma=None, verbose=verbose)\n",
    "        timeb = time.time()\n",
    "        t_temp += timeb - timea\n",
    "        \n",
    "    ts.append(t_temp / num_samples)\n",
    "\n",
    "    t_temp = 0\n",
    "    for i in tqdm(sample_idx):\n",
    "        g = graphs[i]\n",
    "        timea = time.time()\n",
    "        subgraph_mp_transcription(nn, g, S, alpha=alpha, gamma=None, verbose=verbose)\n",
    "        timeb = time.time()\n",
    "        t_temp += timeb - timea\n",
    "    ts.append(t_temp / num_samples)\n",
    "\n",
    "    t_temp = 0\n",
    "    for i in tqdm(sample_idx):\n",
    "        g = graphs[i]\n",
    "        timea = time.time()\n",
    "        subgraph_mp_forward_hook(nn, g, S, alpha=alpha, gamma=None, verbose=verbose)\n",
    "        timeb = time.time()\n",
    "        t_temp += timeb - timea\n",
    "    ts.append(t_temp / num_samples)\n",
    "\n",
    "    model_times.append(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "num_layers = np.arange(1,len(model_times)+1)\n",
    "model_times = np.array(model_times)\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, gridspec_kw={'height_ratios': [3, 1]}, figsize=(3.5,4))\n",
    "fig.subplots_adjust(hspace=0.05)  # adjust space between axes\n",
    "\n",
    "plt.rc('legend', fontsize=14.5) \n",
    "ax2.spines['top'].set_visible(False)\n",
    "\n",
    "for item in ([ax1.title, ax1.xaxis.label, ax1.yaxis.label] +\n",
    "             ax1.get_xticklabels() + ax1.get_yticklabels()):\n",
    "    item.set_fontsize(15)\n",
    "for item in ([ax2.title, ax2.xaxis.label, ax2.yaxis.label] +\n",
    "             ax2.get_xticklabels() + ax2.get_yticklabels()):\n",
    "    item.set_fontsize(15)\n",
    "\n",
    "ax1.set_ylabel(\"Time (s)\")\n",
    "ax2.set_xlabel(r'$L$')\n",
    "plt.xticks(num_layers, [str(i) if i % 2 == 1 else '' for i in range(2,len(model_times)+2)])\n",
    "\n",
    "ax1.plot(num_layers, model_times[:,0], 'c--')\n",
    "line2, = ax1.plot(num_layers, [0]*len(num_layers), 'r-')\n",
    "ax1.legend(['GNN-LRP naive', 'sGNN-LRP'])\n",
    "line2.remove()\n",
    "ax2.plot(num_layers, model_times[:,0], 'c--')\n",
    "ax2.plot(num_layers, model_times[:,2], 'r-')\n",
    "ax1.spines.bottom.set_visible(False)\n",
    "ax2.spines.top.set_visible(False)\n",
    "ax1.xaxis.tick_top()\n",
    "ax1.tick_params(labeltop=False)  # don't put tick labels at the top\n",
    "\n",
    "ax1.set_ylim(0.005)  # outliers only\n",
    "ax2.set_ylim(-0,0.013)\n",
    "\n",
    "d = .5  # proportion of vertical to horizontal extent of the slanted line\n",
    "kwargs = dict(marker=[(-1, -d), (1, d)], markersize=12,\n",
    "              linestyle=\"none\", color='k', mec='k', mew=1, clip_on=False)\n",
    "ax1.plot([0, 1], [0, 0], transform=ax1.transAxes, **kwargs)\n",
    "ax2.plot([0, 1], [1, 1], transform=ax2.transAxes, **kwargs)\n",
    "\n",
    "plt.savefig('imgs/time_consumption_L.eps', dpi=600, format='eps', bbox_inches='tight')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### |S| dependency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs, pos_idx, neg_idx = load_data('BA-2motif')\n",
    "\n",
    "model_dir = 'gin-3-ba2motif.torch'\n",
    "\n",
    "alpha = 0.\n",
    "verbose = False\n",
    "num_samples = 50\n",
    "sample_idx = np.random.choice(len(graphs),num_samples,replace=False)\n",
    "nn = torch.load('models/'+model_dir)\n",
    "\n",
    "model_times = []\n",
    "\n",
    "for size_S in tqdm(range(25)):\n",
    "    S = list(range(size_S))\n",
    "\n",
    "    ts = []\n",
    "    \n",
    "    t_temp = 0\n",
    "    for j, i in tqdm(enumerate(sample_idx)):\n",
    "        g = graphs[i]\n",
    "        timea = time.time()\n",
    "        subgraph_original(nn, g, S, alpha=alpha, gamma=None, verbose=verbose)\n",
    "        timeb = time.time()\n",
    "        t_temp += timeb - timea\n",
    "        \n",
    "    ts.append(t_temp / num_samples)\n",
    "\n",
    "    t_temp = 0\n",
    "    for i in tqdm(sample_idx):\n",
    "        g = graphs[i]\n",
    "        timea = time.time()\n",
    "        subgraph_mp_transcription(nn, g, S, alpha=alpha, gamma=None, verbose=verbose)\n",
    "        timeb = time.time()\n",
    "        t_temp += timeb - timea\n",
    "    ts.append(t_temp / num_samples)\n",
    "\n",
    "    t_temp = 0\n",
    "    for i in tqdm(sample_idx):\n",
    "        g = graphs[i]\n",
    "        timea = time.time()\n",
    "        subgraph_mp_forward_hook(nn, g, S, alpha=alpha, gamma=None, verbose=verbose)\n",
    "        timeb = time.time()\n",
    "        t_temp += timeb - timea\n",
    "    ts.append(t_temp / num_samples)\n",
    "\n",
    "    model_times.append(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "num_layers = np.arange(1,len(model_times)+1)\n",
    "model_times = np.array(model_times)\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, gridspec_kw={'height_ratios': [3, 1]}, figsize=(3.5,4))\n",
    "fig.subplots_adjust(hspace=0.05)  # adjust space between axes\n",
    "ax1.yaxis.tick_right()\n",
    "ax1.yaxis.set_label_position(\"right\")\n",
    "ax2.yaxis.tick_right()\n",
    "\n",
    "plt.rc('legend', fontsize=12)\n",
    "ax2.spines['top'].set_visible(False)\n",
    "\n",
    "for item in ([ax1.title, ax1.xaxis.label, ax1.yaxis.label] +\n",
    "             ax1.get_xticklabels() + ax1.get_yticklabels()):\n",
    "    item.set_fontsize(15)\n",
    "for item in ([ax2.title, ax2.xaxis.label, ax2.yaxis.label] +\n",
    "             ax2.get_xticklabels() + ax2.get_yticklabels()):\n",
    "    item.set_fontsize(15)\n",
    "\n",
    "ax2.set_xlabel(r'$|\\mathcal{S}|$')\n",
    "plt.xticks(num_layers, [str(i) if i % 3 == 1 else '' for i in range(1,len(model_times)+1)])\n",
    "\n",
    "ax1.plot(num_layers, model_times[:,0], 'c--')\n",
    "line2, = ax1.plot(num_layers, [0]*len(num_layers), 'r-')\n",
    "line2.remove()\n",
    "ax2.plot(num_layers, model_times[:,0], 'c--')\n",
    "ax2.plot(num_layers, model_times[:,2], 'r-')\n",
    "\n",
    "ax1.spines.bottom.set_visible(False)\n",
    "ax2.spines.top.set_visible(False)\n",
    "ax1.xaxis.tick_top()\n",
    "ax1.tick_params(labeltop=False)  # don't put tick labels at the top\n",
    "\n",
    "ax1.set_ylim(0.05)  # outliers only\n",
    "ax2.set_ylim(-0,0.01)\n",
    "\n",
    "d = .5  # proportion of vertical to horizontal extent of the slanted line\n",
    "kwargs = dict(marker=[(-1, -d), (1, d)], markersize=12,\n",
    "              linestyle=\"none\", color='k', mec='k', mew=1, clip_on=False)\n",
    "ax1.plot([0, 1], [0, 0], transform=ax1.transAxes, **kwargs)\n",
    "ax2.plot([0, 1], [1, 1], transform=ax2.transAxes, **kwargs)\n",
    "\n",
    "plt.savefig('imgs/time_consumption_S.eps', dpi=600, format='eps', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare time consumptions of the three methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.\n",
    "S = np.arange(5)\n",
    "verbose = True\n",
    "dataset_model_dirs = [['BA-2motif','gin-3-ba2motif.torch'],\n",
    "                      ['BA-2motif','gin-5-ba2motif.torch'],\n",
    "                      ['BA-2motif','gin-7-ba2motif.torch'],\n",
    "                      ['MUTAG', 'gin-3-mutag.torch'],\n",
    "                      ['Mutagenicity', 'gin-3-mutagenicity.torch'],\n",
    "                      ['REDDIT-BINARY', 'gin-5-reddit.torch'],\n",
    "                      ['Graph-SST2', 'gcn-3-sst2graph.torch']]\n",
    "\n",
    "efficiency_result_originals = []\n",
    "efficiency_result_mp_transcs = []\n",
    "efficiency_result_forward_hooks = []\n",
    "\n",
    "for dataset, model_dir in dataset_model_dirs:\n",
    "    print(dataset, model_dir)\n",
    "    graphs, pos_idx, neg_idx = load_data(dataset)\n",
    "\n",
    "    nn = torch.load('models/'+model_dir)\n",
    "    s = StringIO()\n",
    "    old_stdout = sys.stdout\n",
    "    sys.stdout = s\n",
    "    lists = []\n",
    "\n",
    "    for _ in tqdm(range(50)):\n",
    "        i = np.random.randint(len(graphs))\n",
    "        g = graphs[i]\n",
    "\n",
    "        while g.nbnodes < 5:\n",
    "            i = np.random.randint(len(graphs))\n",
    "            g = graphs[i]\n",
    "\n",
    "        for _ in range(3):\n",
    "            subgraph_original(nn, g, S, alpha=alpha, gamma=None, verbose=verbose)\n",
    "            subgraph_mp_transcription(nn, g, S, alpha=alpha, gamma=None, verbose=verbose)\n",
    "            subgraph_mp_forward_hook(nn, g, S, alpha=alpha, gamma=None, verbose=verbose)\n",
    "    lists = s.getvalue().splitlines()\n",
    "\n",
    "    sys.stdout = old_stdout\n",
    "\n",
    "    lists_ = [[float(data.split(': ')[-1].split(',')[0]) for data in l.split('\\t')[1:]] for l in lists]\n",
    "\n",
    "    efficiency_result_original = pd.DataFrame(lists_[::3],columns=['nbnodes','layers','overhead','subrel'])\n",
    "    efficiency_result_mp_transc = pd.DataFrame(lists_[1::3],columns=['nbnodes','layers','overhead','subrel'])\n",
    "    efficiency_result_forward_hook = pd.DataFrame(lists_[2::3],columns=['nbnodes','layers','forward1','backward1'])\n",
    "\n",
    "    efficiency_result_originals.append(efficiency_result_original.mean(axis=0))\n",
    "    efficiency_result_mp_transcs.append(efficiency_result_mp_transc.mean(axis=0))\n",
    "    efficiency_result_forward_hooks.append(efficiency_result_forward_hook.mean(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test different alphas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ACC AUC AUPC AUFC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = False\n",
    "test_samples = 200\n",
    "\n",
    "# BA-2motif\n",
    "dataset = 'BA-2motif'\n",
    "graphs, pos_idx, neg_idx = load_data('BA-2motif')\n",
    "model_dir = \"models/gin-3-ba2motif.torch\"; num_layer= 3\n",
    "nn = torch.load(model_dir)\n",
    "\n",
    "# # MUTAG\n",
    "# dataset = 'MUTAG'\n",
    "# graphs, pos_idx, neg_idx = load_data('MUTAG')\n",
    "# model_dir = \"models/gin-3-mutag.torch\"; num_layer= 3\n",
    "# nn = torch.load(model_dir)\n",
    "\n",
    "# # Graph-SST2\n",
    "# dataset = 'Graph-SST2'\n",
    "# graphs, pos_idx, neg_idx = load_data('Graph-SST2')\n",
    "# model_dir = \"models/gcn-3-sst2graph.torch\"; num_layer= 3\n",
    "# nn = torch.load(model_dir)\n",
    "\n",
    "message = '{}\\nModel depth: {}, model: {}, nb of samples: {}\\n'.format(model_dir,num_layer, 'gin', test_samples)\n",
    "print(message)\n",
    "\n",
    "messages = []\n",
    "test_sample_idx = []\n",
    "for alpha in np.arange(0.0,1.01,0.05):\n",
    "    if dataset == 'BA-2motif':\n",
    "        stats = {'acc': [], 'auc': [], 'auac': [], 'aupc': [], 'acs': [], 'pcs': [], 'label': []}\n",
    "    else:\n",
    "        stats = {'auac': [], 'aupc': [], 'acs': [], 'pcs': [], 'label': []}\n",
    "    cnt_pos = test_samples / 2\n",
    "    cnt_neg = test_samples / 2\n",
    "    start = time.time()\n",
    "    random_sample = True if test_sample_idx == [] else False\n",
    "    i = 0\n",
    "    while cnt_pos > 0 or cnt_neg > 0:\n",
    "        if random_sample:\n",
    "            idx = np.random.randint(len(graphs))\n",
    "            g = graphs[idx]\n",
    "            if g.nbnodes < 3: continue\n",
    "            if g.label == 0:\n",
    "                if cnt_pos == 0: continue\n",
    "                else: cnt_pos -= 1\n",
    "            else:\n",
    "                if cnt_neg == 0: continue\n",
    "                else: cnt_neg -= 1\n",
    "            test_sample_idx.append(idx)\n",
    "        else:\n",
    "            if i >= len(test_sample_idx): break\n",
    "            g = graphs[test_sample_idx[i]]\n",
    "            i += 1\n",
    "\n",
    "        gr_tr, all_feats = create_ground_truth(g)\n",
    "\n",
    "        # mode = 'prun'\n",
    "        mode = 'extr'\n",
    "\n",
    "        H, transforms = get_H_transform(g.get_adj(),nn,gammas=None)\n",
    "        fo = get_feat_order_local_best_guess(nn, g, alpha, H, transforms, mode='extr')\n",
    "        \n",
    "        if mode == 'extr':\n",
    "            acc, auc = get_stats(gr_tr, fo, all_feats)\n",
    "            auac, acs = get_auac_aupc(nn, g, fo, task=mode, use_softmax=True)\n",
    "            aupc, pcs = [], []\n",
    "        else:\n",
    "            acc, auc = [], []\n",
    "            aupc, pcs = get_auac_aupc(nn, g, fo, task=mode, use_softmax=False)\n",
    "            auac, acs = [], []\n",
    "\n",
    "        if dataset == 'BA-2motif':\n",
    "            stats['acc'].append(acc)\n",
    "            stats['auc'].append(auc)\n",
    "        stats['auac'].append(auac)\n",
    "        stats['aupc'].append(aupc)\n",
    "        stats['acs'].append(acs)\n",
    "        stats['pcs'].append(pcs)\n",
    "        stats['label'].append(g.label)\n",
    "\n",
    "    message = 'alpha {}, took {} s\\n'.format(alpha, round(time.time() - start, 4))\n",
    "    for key, lst in  stats.items():\n",
    "        if key in ['acs', 'pcs', 'label']: continue\n",
    "        elif key in ['acc', 'auc']:\n",
    "            mstat = round(sum(lst)/len(lst), 4)\n",
    "            message += '\\t {} : {}'.format(key, mstat)\n",
    "        elif key in ['auac', 'aupc']:\n",
    "            lst = np.array(lst)\n",
    "            pos = list(np.argwhere(np.array(stats['label']) == 0).flatten())\n",
    "            mstat = round(np.sum(lst[pos])/len(pos), 4)\n",
    "            message += '\\t {}_pos : {}'.format(key, mstat)\n",
    "            neg = list(np.argwhere(np.array(stats['label']) == 1).flatten())\n",
    "            mstat = round(np.sum(lst[neg])/len(neg), 4)\n",
    "            message += '\\t {}_neg : {}'.format(key, mstat)\n",
    "            mstat = round(np.sum(lst)/len(lst), 4)\n",
    "            message += '\\t {} : {}'.format(key, mstat)\n",
    "    message += '\\n'\n",
    "\n",
    "    print(message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot acc auc\n",
    "\n",
    "with open('evaluation_results/result_local_best_guess.txt','r') as f:\n",
    "    s = f.readlines()[2:]\n",
    "stats = {}\n",
    "for i in range(len(s)//2):\n",
    "    alpha = float(s[i * 2].split(',')[0].split(' ')[-1])\n",
    "    for sss in s[i * 2 + 1].split('\\n')[0].split('\\t')[1:]:\n",
    "        sss = sss.split(':')\n",
    "        if sss[0].strip() not in stats:\n",
    "            stats[sss[0].strip()] = []\n",
    "        stats[sss[0].strip()].append(float(sss[1]))\n",
    "fig, ax = plt.subplots(figsize=(5,1.5))\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.spines['top'].set_visible(False)\n",
    "\n",
    "for item in ([ax.title, ax.xaxis.label, ax.yaxis.label] +\n",
    "             ax.get_xticklabels() + ax.get_yticklabels()):\n",
    "    item.set_fontsize(15)\n",
    "plt.rc('legend', fontsize=15)  \n",
    "\n",
    "plt.plot(np.arange(0,1.01,0.05),stats['acc'], 'r-')\n",
    "plt.plot(np.arange(0,1.01,0.05),stats['auc'], 'b--')\n",
    "plt.legend([\"Accuracy\", \"AUROC\"])\n",
    "plt.xlim(0,1)\n",
    "plt.ylim(top=1)\n",
    "plt.xlabel(r'$\\alpha$')\n",
    "# plt.xticks(np.arange(0,1.01,0.05))\n",
    "plt.savefig('imgs/ba2motif_acc_auc.eps', dpi=600, format='eps', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot aupc aufc\n",
    "\n",
    "# data_dir = 'evaluation_results/mutag_prun_result.txt'; dataset = 'mutag'\n",
    "# data_dir = 'evaluation_results/mutag_acti_result.txt'; dataset = 'mutag'\n",
    "# data_dir = 'evaluation_results/graphsst2_prun_result.txt'; dataset = 'graphsst2'\n",
    "data_dir = 'evaluation_results/graphsst2_acti_result.txt'; dataset = 'graphsst2'\n",
    "\n",
    "with open(data_dir,'r') as f:\n",
    "    s = f.readlines()[2:]\n",
    "stats = {}\n",
    "for i in range(len(s)//2):\n",
    "    alpha = float(s[i * 2].split(',')[0].split(' ')[-1])\n",
    "    for sss in s[i * 2 + 1].split('\\n')[0].split('\\t')[1:]:\n",
    "        sss = sss.split(':')\n",
    "        if sss[0].strip() not in stats:\n",
    "            stats[sss[0].strip()] = []\n",
    "        stats[sss[0].strip()].append(float(sss[1]))\n",
    "\n",
    "fig = plt.figure(figsize=(3,3))\n",
    "ax1 = fig.add_subplot(111)\n",
    "\n",
    "for item in ([ax1.title, ax1.xaxis.label, ax1.yaxis.label] +\n",
    "             ax1.get_xticklabels() + ax1.get_yticklabels()):\n",
    "    item.set_fontsize(15)\n",
    "\n",
    "if 'aupc_pos' in stats.keys():\n",
    "    key = 'aupc_pos'\n",
    "    ax1.annotate(xy=(np.argmin(stats[key])*0.05,np.min(stats[key])), text='', \n",
    "                 xytext=(np.argmin(stats[key])*0.05,np.min(stats[key])-0.15), arrowprops={'arrowstyle':'->','color':'red'})\n",
    "else:\n",
    "    key = 'auac_pos'\n",
    "    ax1.annotate(xy=(np.argmax(stats[key])*0.05,np.max(stats[key])), text='', \n",
    "                 xytext=(np.argmax(stats[key])*0.05,np.max(stats[key])-0.25), arrowprops={'arrowstyle':'->','color':'red'})\n",
    "ax1.plot(np.arange(0,1.01,0.05),stats[key], 'r-')\n",
    "\n",
    "ax1.set_ylabel('positive')\n",
    "ax1.yaxis.label.set_color('red')\n",
    "ax1.tick_params(axis='y', colors='red')\n",
    "ax1.set_xlabel(r'$\\alpha$')\n",
    "\n",
    "ax2 = ax1.twinx()\n",
    "for item in ([ax2.title, ax2.xaxis.label, ax2.yaxis.label] +\n",
    "             ax2.get_xticklabels() + ax2.get_yticklabels()):\n",
    "    item.set_fontsize(15)\n",
    "if 'aupc_neg' in stats.keys():\n",
    "    key = 'aupc_neg'\n",
    "    ax2.annotate(xy=(np.argmin(stats[key])*0.05,np.min(stats[key])), text='', \n",
    "                 xytext=(np.argmin(stats[key])*0.05,np.min(stats[key])-0.15), arrowprops={'arrowstyle':'->','color':'blue'})\n",
    "else:\n",
    "    key = 'auac_neg'\n",
    "    ax2.annotate(xy=(np.argmax(stats[key])*0.05,np.max(stats[key])), text='', \n",
    "                 xytext=(np.argmax(stats[key])*0.05,np.max(stats[key])-0.25), \n",
    "                 arrowprops={'arrowstyle':'->','color':'blue'})\n",
    "\n",
    "ax2.set_ylabel('negative')\n",
    "ax2.yaxis.label.set_color('blue')\n",
    "ax2.tick_params(axis='y', colors='blue')\n",
    "\n",
    "ax2.plot(np.arange(0,1.01,0.05),stats[key], 'b--')\n",
    "ax2.set_xlim(0,1)\n",
    "ax2.set_xlabel(r'$\\alpha$')\n",
    "\n",
    "if 'aupc_neg' in stats.keys():\n",
    "    plt.savefig('imgs/'+dataset+'_aupc.eps', dpi=600, format='eps',bbox_inches='tight')\n",
    "else:\n",
    "    plt.savefig('imgs/'+dataset+'_auac.eps', dpi=600, format='eps',bbox_inches='tight')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8806367dad1e0a2cfd7da8c1ed95d51b1c4f8061d16620a9f0a678416f1237e6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
