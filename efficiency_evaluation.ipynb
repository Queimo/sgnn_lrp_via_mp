{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from load_data import load_data\n",
    "import torch\n",
    "from modules import GNN\n",
    "from train_model import train_model\n",
    "from subgraph_relevance import subgraph_original, subgraph_mp_transcription, subgraph_mp_forward_hook\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import pandas as pd\n",
    "from io import StringIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a function of model layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs, pos_idx, neg_idx = load_data('BA-2motif')\n",
    "\n",
    "model_dirs = ['gin-2-ba2motif.torch',\n",
    "            'gin-3-ba2motif.torch',\n",
    "            'gin-4-ba2motif.torch',\n",
    "            'gin-5-ba2motif.torch',\n",
    "            'gin-6-ba2motif.torch',\n",
    "            'gin-7-ba2motif.torch']\n",
    "\n",
    "# g = graphs[44]\n",
    "S = [0,1,2,3]\n",
    "alpha = 0.\n",
    "verbose = False\n",
    "num_samples = 50\n",
    "sample_idx = np.random.choice(len(graphs),num_samples,replace=False)\n",
    "\n",
    "model_times = []\n",
    "\n",
    "for model_dir in tqdm(model_dirs):\n",
    "    ts = []\n",
    "    nn = torch.load('models/'+model_dir)\n",
    "    \n",
    "    t_temp = 0\n",
    "    for j, i in tqdm(enumerate(sample_idx)):\n",
    "        g = graphs[i]\n",
    "        timea = time.time()\n",
    "        subgraph_original(nn, g, S, alpha=alpha, gamma=None, verbose=verbose)\n",
    "        timeb = time.time()\n",
    "        t_temp += timeb - timea\n",
    "        \n",
    "    ts.append(t_temp / num_samples)\n",
    "\n",
    "    t_temp = 0\n",
    "    for i in tqdm(sample_idx):\n",
    "        g = graphs[i]\n",
    "        timea = time.time()\n",
    "        subgraph_mp_transcription(nn, g, S, alpha=alpha, gamma=None, verbose=verbose)\n",
    "        timeb = time.time()\n",
    "        t_temp += timeb - timea\n",
    "    ts.append(t_temp / num_samples)\n",
    "\n",
    "    t_temp = 0\n",
    "    for i in tqdm(sample_idx):\n",
    "        g = graphs[i]\n",
    "        timea = time.time()\n",
    "        subgraph_mp_forward_hook(nn, g, S, alpha=alpha, gamma=None, verbose=verbose)\n",
    "        timeb = time.time()\n",
    "        t_temp += timeb - timea\n",
    "    ts.append(t_temp / num_samples)\n",
    "\n",
    "    model_times.append(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time & model layers\n",
    "model_times = [[3.79432821e-02, 2.85856771e-02, 2.11679459e-03],\n",
    "       [2.24222307e-01, 5.61089563e-02, 4.21986103e-03],\n",
    "       [1.21142797e+00, 8.27891207e-02, 5.42837620e-03],\n",
    "       [6.06633543e+00, 9.72466040e-02, 6.44898415e-03],\n",
    "       [3.09617811e+01, 1.18584792e-01, 8.30366135e-03],\n",
    "       [1.42194685e+02, 1.39745464e-01, 9.81472492e-03]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "num_layers = np.arange(1,len(model_times)+1)\n",
    "model_times = np.array(model_times)\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, gridspec_kw={'height_ratios': [3, 1]}, figsize=(3,4))\n",
    "fig.subplots_adjust(hspace=0.05)  # adjust space between axes\n",
    "\n",
    "plt.rc('legend', fontsize=12) \n",
    "ax2.spines['top'].set_visible(False)\n",
    "\n",
    "for item in ([ax1.title, ax1.xaxis.label, ax1.yaxis.label] +\n",
    "             ax1.get_xticklabels() + ax1.get_yticklabels()):\n",
    "    item.set_fontsize(15)\n",
    "for item in ([ax2.title, ax2.xaxis.label, ax2.yaxis.label] +\n",
    "             ax2.get_xticklabels() + ax2.get_yticklabels()):\n",
    "    item.set_fontsize(15)\n",
    "\n",
    "ax1.set_ylabel(\"Time (s)\")\n",
    "ax2.set_xlabel(r'$L$')\n",
    "plt.xticks(num_layers, [str(i) if i % 2 == 1 else '' for i in range(1,len(model_times)+1)])\n",
    "\n",
    "ax1.plot(num_layers, model_times[:,0], 'r-')\n",
    "line2, = ax1.plot(num_layers, [0]*len(num_layers), 'b-.')\n",
    "ax1.legend(['GNN-LRP naive', 'sGNN-LRP'])\n",
    "line2.remove()\n",
    "ax2.plot(num_layers, model_times[:,0], 'r-')\n",
    "ax2.plot(num_layers, model_times[:,2], 'b-.')\n",
    "ax1.spines.bottom.set_visible(False)\n",
    "ax2.spines.top.set_visible(False)\n",
    "ax1.xaxis.tick_top()\n",
    "ax1.tick_params(labeltop=False)  # don't put tick labels at the top\n",
    "\n",
    "ax1.set_ylim(0.005)  # outliers only\n",
    "ax2.set_ylim(-0,0.013)\n",
    "\n",
    "d = .5  # proportion of vertical to horizontal extent of the slanted line\n",
    "kwargs = dict(marker=[(-1, -d), (1, d)], markersize=12,\n",
    "              linestyle=\"none\", color='k', mec='k', mew=1, clip_on=False)\n",
    "ax1.plot([0, 1], [0, 0], transform=ax1.transAxes, **kwargs)\n",
    "ax2.plot([0, 1], [1, 1], transform=ax2.transAxes, **kwargs)\n",
    "\n",
    "plt.savefig('imgs/time_consumption_L.eps', dpi=600, format='eps', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a function of subgraph size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs, pos_idx, neg_idx = load_data('BA-2motif')\n",
    "\n",
    "model_dir = 'gin-3-ba2motif.torch'\n",
    "\n",
    "alpha = 0.\n",
    "verbose = False\n",
    "num_samples = 50\n",
    "sample_idx = np.random.choice(len(graphs),num_samples,replace=False)\n",
    "nn = torch.load('models/'+model_dir)\n",
    "\n",
    "model_times = []\n",
    "\n",
    "for size_S in tqdm(range(25)):\n",
    "    S = list(range(size_S))\n",
    "\n",
    "    ts = []\n",
    "    \n",
    "    t_temp = 0\n",
    "    for j, i in tqdm(enumerate(sample_idx)):\n",
    "        g = graphs[i]\n",
    "        timea = time.time()\n",
    "        subgraph_original(nn, g, S, alpha=alpha, gamma=None, verbose=verbose)\n",
    "        timeb = time.time()\n",
    "        t_temp += timeb - timea\n",
    "        \n",
    "    ts.append(t_temp / num_samples)\n",
    "\n",
    "    t_temp = 0\n",
    "    for i in tqdm(sample_idx):\n",
    "        g = graphs[i]\n",
    "        timea = time.time()\n",
    "        subgraph_mp_transcription(nn, g, S, alpha=alpha, gamma=None, verbose=verbose)\n",
    "        timeb = time.time()\n",
    "        t_temp += timeb - timea\n",
    "    ts.append(t_temp / num_samples)\n",
    "\n",
    "    t_temp = 0\n",
    "    for i in tqdm(sample_idx):\n",
    "        g = graphs[i]\n",
    "        timea = time.time()\n",
    "        subgraph_mp_forward_hook(nn, g, S, alpha=alpha, gamma=None, verbose=verbose)\n",
    "        timeb = time.time()\n",
    "        t_temp += timeb - timea\n",
    "    ts.append(t_temp / num_samples)\n",
    "\n",
    "    model_times.append(ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time & subgraph size\n",
    "model_times = [[0.0046125841140747074, 0.07880849838256836, 0.004756159782409668],\n",
    " [0.03629368782043457, 0.0721881341934204, 0.0038048934936523436],\n",
    " [0.09700009346008301, 0.06509144306182861, 0.004636597633361816],\n",
    " [0.22644277095794677, 0.06653767108917236, 0.0055991697311401365],\n",
    " [0.44647380352020266, 0.06331422805786133, 0.004125766754150391],\n",
    " [0.7955206298828125, 0.0697042989730835, 0.004573965072631836],\n",
    " [1.244990677833557, 0.05818732738494873, 0.0046390676498413086],\n",
    " [1.9092957782745361, 0.06346342086791992, 0.004363369941711426],\n",
    " [2.6129654121398924, 0.05599023818969726, 0.004363474845886231],\n",
    " [3.686415991783142, 0.05271221160888672, 0.004402637481689453],\n",
    " [4.913209948539734, 0.06820619106292725, 0.004435920715332031],\n",
    " [6.259419693946838, 0.055459322929382326, 0.0032729005813598635],\n",
    " [8.146011185646056, 0.06872797012329102, 0.003718433380126953],\n",
    " [10.04942915916443, 0.06456290721893311, 0.0037899065017700196],\n",
    " [12.10968173980713, 0.05984879970550537, 0.0038155269622802733],\n",
    " [15.019109363555907, 0.06313271999359131, 0.0058210515975952145],\n",
    " [18.107507333755493, 0.07190500736236573, 0.003952789306640625],\n",
    " [22.159293155670166, 0.06416292667388916, 0.004039020538330078],\n",
    " [25.479938478469847, 0.06957473278045655, 0.00435152530670166]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting\n",
    "num_layers = np.arange(1,len(model_times)+1)\n",
    "model_times = np.array(model_times)\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, gridspec_kw={'height_ratios': [3, 1]}, figsize=(3,4))\n",
    "fig.subplots_adjust(hspace=0.05)  # adjust space between axes\n",
    "ax1.yaxis.tick_right()\n",
    "ax1.yaxis.set_label_position(\"right\")\n",
    "ax2.yaxis.tick_right()\n",
    "\n",
    "plt.rc('legend', fontsize=12)\n",
    "ax2.spines['top'].set_visible(False)\n",
    "\n",
    "for item in ([ax1.title, ax1.xaxis.label, ax1.yaxis.label] +\n",
    "             ax1.get_xticklabels() + ax1.get_yticklabels()):\n",
    "    item.set_fontsize(15)\n",
    "for item in ([ax2.title, ax2.xaxis.label, ax2.yaxis.label] +\n",
    "             ax2.get_xticklabels() + ax2.get_yticklabels()):\n",
    "    item.set_fontsize(15)\n",
    "\n",
    "ax2.set_xlabel(r'$|\\mathcal{S}|$')\n",
    "plt.xticks(num_layers, [str(i) if i % 3 == 1 else '' for i in range(1,len(model_times)+1)])\n",
    "\n",
    "ax1.plot(num_layers, model_times[:,0], 'r-')\n",
    "line2, = ax1.plot(num_layers, [0]*len(num_layers), 'b-.')\n",
    "line2.remove()\n",
    "ax2.plot(num_layers, model_times[:,0], 'r-')\n",
    "ax2.plot(num_layers, model_times[:,2], 'b-.')\n",
    "\n",
    "ax1.spines.bottom.set_visible(False)\n",
    "ax2.spines.top.set_visible(False)\n",
    "ax1.xaxis.tick_top()\n",
    "ax1.tick_params(labeltop=False)  # don't put tick labels at the top\n",
    "\n",
    "ax1.set_ylim(0.05)  # outliers only\n",
    "ax2.set_ylim(-0,0.01)\n",
    "\n",
    "d = .5  # proportion of vertical to horizontal extent of the slanted line\n",
    "kwargs = dict(marker=[(-1, -d), (1, d)], markersize=12,\n",
    "              linestyle=\"none\", color='k', mec='k', mew=1, clip_on=False)\n",
    "ax1.plot([0, 1], [0, 0], transform=ax1.transAxes, **kwargs)\n",
    "ax2.plot([0, 1], [1, 1], transform=ax2.transAxes, **kwargs)\n",
    "\n",
    "plt.savefig('imgs/time_consumption_S.eps', dpi=600, format='eps', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare time consumptions of three methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.\n",
    "S = np.arange(5)\n",
    "\n",
    "model_dirs = ['gin-3-ba2motif.torch',\n",
    "            'gin-5-ba2motif.torch',\n",
    "            'gin-7-ba2motif.torch']\n",
    "\n",
    "efficiency_result_originals = []\n",
    "efficiency_result_mp_transcs = []\n",
    "efficiency_result_forward_hooks = []\n",
    "\n",
    "for model_dir in model_dirs:\n",
    "    nn = torch.load(model_dir)\n",
    "    s = StringIO()\n",
    "    old_stdout = sys.stdout\n",
    "    sys.stdout = s\n",
    "    lists = []\n",
    "\n",
    "    for i in tqdm(range(50)):\n",
    "        g = graphs[i]\n",
    "        for _ in range(3):\n",
    "            subgraph_original(nn, g, S, alpha=alpha, gamma=None, verbose=verbose)\n",
    "            subgraph_mp_transcription(nn, g, S, alpha=alpha, gamma=None, verbose=verbose)\n",
    "            subgraph_mp_forward_hook(nn, g, S, alpha=alpha, gamma=None, verbose=verbose)\n",
    "    lists = s.getvalue().splitlines()\n",
    "\n",
    "    sys.stdout = old_stdout\n",
    "\n",
    "    lists_ = [[float(data.split(': ')[-1].split(',')[0]) for data in l.split('\\t')[1:]] for l in lists]\n",
    "\n",
    "    efficiency_result_original = pd.DataFrame(lists_[::3],columns=['nbnodes','layers','overhead','subrel'])\n",
    "    efficiency_result_mp_transc = pd.DataFrame(lists_[1::3],columns=['nbnodes','layers','overhead','subrel'])\n",
    "    efficiency_result_forward_hook = pd.DataFrame(lists_[2::3],columns=['nbnodes','layers','forward1','backward1'])\n",
    "\n",
    "    efficiency_result_originals.append(efficiency_result_original.mean(axis=0))\n",
    "    efficiency_result_mp_transcs.append(efficiency_result_mp_transc.mean(axis=0))\n",
    "    efficiency_result_forward_hooks.append(efficiency_result_forward_hook.mean(axis=0))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8806367dad1e0a2cfd7da8c1ed95d51b1c4f8061d16620a9f0a678416f1237e6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
