{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from load_data import load_data\n",
    "import torch\n",
    "from modules import GNN\n",
    "from train_model import train_model\n",
    "from subgraph_relevance import subgraph_original, subgraph_mp_transcription, subgraph_mp_forward_hook\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_graphs: 70042\n"
     ]
    }
   ],
   "source": [
    "graphs, pos_idx, neg_idx = load_data('BA-2motif')\n",
    "\n",
    "config = {\n",
    "        'num_layer': 3,\n",
    "        'mode': 'gin',\n",
    "        'epochs': 1000,\n",
    "        'lr': 0.00001,\n",
    "        'model_dir': 'models/ttttgtin-8-ba2motif.torch',\n",
    "        'nbclasses': 2,\n",
    "        'inter_feat_dim': 20,\n",
    "        'print_out_nb': 10,\n",
    "        'optimizer': 'sgd'\n",
    "    }\n",
    "\n",
    "dataset = graphs\n",
    "train_idx = np.arange(400).tolist() + np.arange(500,900).tolist()\n",
    "test_idx = np.arange(400,500).tolist() + np.arange(900,1000).tolist()\n",
    "train_model(dataset, train_idx, test_idx, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_graphs: 70042\n",
      "original\tnbnodes: 7,\tlayers: 3,\toverhead: 0.090759,\tsubrel: 0.000819\n",
      "tensor(3.2917) 0.09715914726257324\n",
      "mp_transc\tnbnodes: 7,\tlayers: 3,\toverhead: 0.006494,\tsubrel: 0.013033\n",
      "tensor(3.2917) 0.02008986473083496\n",
      "forward_hook\tnbnodes: 7,\tlayers: 3,\tforward: 0.002394,\tbackward: 0.006962\n",
      "tensor(3.2917) 0.009769201278686523\n"
     ]
    }
   ],
   "source": [
    "graphs, pos_idx, neg_idx = load_data('BA-2motif')\n",
    "nn: GNN = torch.load('models/gin-3-ba2motif.torch')\n",
    "\n",
    "graphs, pos_idx, neg_idx = load_data('MUTAG')\n",
    "nn: GNN = torch.load('models/gin-3-mutag.torch')\n",
    "\n",
    "graphs, pos_idx, neg_idx = load_data('Mutagenicity')\n",
    "nn: GNN = torch.load('models/gin-3-mutagenicity.torch')\n",
    "\n",
    "graphs, pos_idx, neg_idx = load_data('REDDIT-BINARY') # subgraph_mp_transcription timeout\n",
    "nn: GNN = torch.load('models/gin-5-reddit.torch')\n",
    "\n",
    "graphs, pos_idx, neg_idx = load_data('Graph-SST2')\n",
    "nn: GNN = torch.load('models/gcn-3-sst2graph.torch')\n",
    "\n",
    "S = [0,1,2,3]\n",
    "alpha = 0.\n",
    "verbose = True\n",
    "\n",
    "g = graphs[0]\n",
    "timea = time.time()\n",
    "print(subgraph_original(nn, g, S, alpha=alpha, gamma=None, verbose=verbose), f\"{time.time() - timea}\")\n",
    "\n",
    "timea = time.time()\n",
    "print(subgraph_mp_transcription(nn, g, S, alpha=alpha, gamma=None, verbose=verbose), f\"{time.time() - timea}\")\n",
    "timea = time.time()\n",
    "print(subgraph_mp_forward_hook(nn, g, S, alpha=alpha, gamma=None, verbose=verbose), f\"{time.time() - timea}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8806367dad1e0a2cfd7da8c1ed95d51b1c4f8061d16620a9f0a678416f1237e6"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
